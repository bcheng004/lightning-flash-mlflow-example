{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "InteractiveShell.ast_node_interactivity = 'last_expr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "mlflow_uri = config['mlflow']['mlflow_uri']\n",
    "mlflow_artifact_uri = config['mlflow']['target_mlflow_artifact_uri']\n",
    "linux_mlflow_artifact_uri = config['mlflow']['linux_target_mlflow_artifact_uri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chengb/.local/lib/python3.8/site-packages/pytorch_lightning/metrics/__init__.py:43: LightningDeprecationWarning: `pytorch_lightning.metrics.*` module has been renamed to `torchmetrics.*` and split off to its own package (https://github.com/PyTorchLightning/metrics) since v1.3 and will be removed in v1.5\n",
      "  rank_zero_deprecation(\n"
     ]
    }
   ],
   "source": [
    "import flash\n",
    "from flash.core.data.utils import download_data\n",
    "\n",
    "download_data(config['text-example']['download_url'], 'data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default-dfd46f69c7ce0a0f (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /home/chengb/.cache/huggingface/datasets/csv/default-dfd46f69c7ce0a0f/0.0.0/2960f95a26e85d40ca41a230ac88787f715ee3003edaacb8b1f0891e9f04dda2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/chengb/.cache/huggingface/datasets/csv/default-dfd46f69c7ce0a0f/0.0.0/2960f95a26e85d40ca41a230ac88787f715ee3003edaacb8b1f0891e9f04dda2. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "600f55663a0b4b5786f97f3667c103b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=22500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4895bc8748c44730a53d898267f98356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=23.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default-bda365d4e302bf56 (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /home/chengb/.cache/huggingface/datasets/csv/default-bda365d4e302bf56/0.0.0/2960f95a26e85d40ca41a230ac88787f715ee3003edaacb8b1f0891e9f04dda2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/chengb/.cache/huggingface/datasets/csv/default-bda365d4e302bf56/0.0.0/2960f95a26e85d40ca41a230ac88787f715ee3003edaacb8b1f0891e9f04dda2. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "909ec9f5c94e487990da7d06ff0e4a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bac4b4a8ec444a6ac8f8ecac11f9161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default-d5c8705a313a84e1 (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /home/chengb/.cache/huggingface/datasets/csv/default-d5c8705a313a84e1/0.0.0/2960f95a26e85d40ca41a230ac88787f715ee3003edaacb8b1f0891e9f04dda2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/chengb/.cache/huggingface/datasets/csv/default-d5c8705a313a84e1/0.0.0/2960f95a26e85d40ca41a230ac88787f715ee3003edaacb8b1f0891e9f04dda2. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3be5eee3ec04ce796b88421f8d6fda7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "773b02166e8b4e4487461b87a485e988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from flash.text import TextClassificationData, TextClassifier\n",
    "\n",
    "input_fields,target_fields = 'review', 'sentiment'\n",
    "batch_size=512\n",
    "datamodule = TextClassificationData.from_csv(\n",
    "    train_file=config['text-example']['train_file'],\n",
    "    val_file=config['text-example']['val_file'],\n",
    "    test_file=config['text-example']['test_file'],\n",
    "    input_fields=input_fields,\n",
    "    target_fields=target_fields,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-mini were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-mini and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TextClassifier(num_classes=datamodule.num_classes, backbone='prajjwal1/bert-mini')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Backbone** Can be seen on huggingface: [huggingface-link](https://huggingface.co/prajjwal1/bert-mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pytorch_lightning.loggers import MLFlowLogger\n",
    "\n",
    "username = os.getenv(\"uid\")\n",
    "mlf_logger = MLFlowLogger(experiment_name=f'lightning-flash-{username}-bert', tracking_uri=mlflow_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    " trainer = flash.Trainer(logger=mlf_logger, max_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Experiment with name lightning-flash-chengb-bert not found. Creating it.\n",
      "\n",
      "  | Name    | Type                          | Params\n",
      "----------------------------------------------------------\n",
      "0 | metrics | ModuleDict                    | 0     \n",
      "1 | model   | BertForSequenceClassification | 11.2 M\n",
      "----------------------------------------------------------\n",
      "514       Trainable params\n",
      "11.2 M    Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.684    Total estimated model params size (MB)\n",
      "Epoch 0:  92%|█████████▏| 44/48 [12:48<01:09, 17.46s/it, loss=0.648, v_num=da32, val_accuracy=0.504, val_cross_entropy=0.723, train_accuracy_step=0.666, train_cross_entropy_step=0.628]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▍| 45/48 [13:03<00:52, 17.42s/it, loss=0.648, v_num=da32, val_accuracy=0.504, val_cross_entropy=0.723, train_accuracy_step=0.666, train_cross_entropy_step=0.628]\n",
      "Epoch 0:  96%|█████████▌| 46/48 [13:18<00:34, 17.35s/it, loss=0.648, v_num=da32, val_accuracy=0.504, val_cross_entropy=0.723, train_accuracy_step=0.666, train_cross_entropy_step=0.628]\n",
      "Epoch 0:  98%|█████████▊| 47/48 [13:35<00:17, 17.35s/it, loss=0.648, v_num=da32, val_accuracy=0.504, val_cross_entropy=0.723, train_accuracy_step=0.666, train_cross_entropy_step=0.628]\n",
      "Epoch 0: 100%|██████████| 48/48 [13:53<00:00, 17.36s/it, loss=0.648, v_num=da32, val_accuracy=0.504, val_cross_entropy=0.723, train_accuracy_step=0.666, train_cross_entropy_step=0.628]\n",
      "Epoch 0: 100%|██████████| 48/48 [14:09<00:00, 17.70s/it, loss=0.648, v_num=da32, val_accuracy=0.675, val_cross_entropy=0.612, train_accuracy_step=0.643, train_cross_entropy_step=0.645, train_accuracy_epoch=0.578, train_cross_entropy_epoch=0.718]\n",
      "Epoch 0: 100%|██████████| 48/48 [14:10<00:00, 17.71s/it, loss=0.648, v_num=da32, val_accuracy=0.675, val_cross_entropy=0.612, train_accuracy_step=0.643, train_cross_entropy_step=0.645, train_accuracy_epoch=0.578, train_cross_entropy_epoch=0.718]\n"
     ]
    }
   ],
   "source": [
    "trainer.finetune(model, datamodule=datamodule, strategy=\"freeze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 5/5 [01:08<00:00, 13.78s/it]\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_accuracy': 0.6736000180244446, 'test_cross_entropy': 0.6115491986274719}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_accuracy': 0.6736000180244446,\n",
       "  'test_cross_entropy': 0.6115491986274719}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If one is training on windows laptop or training on linux blade\n",
    "import shutil\n",
    "import platform\n",
    "\n",
    "exp_num = '143'\n",
    "if platform.system() == 'Windows':\n",
    "    file_names = os.listdir()\n",
    "    current_artifact_base_fpath = os.getcwd()\n",
    "    source_dir = f'{current_artifact_base_fpath}'\n",
    "    target_dir = mlflow_artifact_uri\n",
    "    for file_name in file_names:\n",
    "        if file_name  == exp_num:\n",
    "            for subfolder in os.listdir(file_name):\n",
    "                for artifacts in os.listdir(os.path.join(file_name,subfolder)):\n",
    "                    if artifacts == 'checkpoints':\n",
    "                        orig_artifacts_loc = os.path.join(os.path.join(os.path.join(source_dir, file_name), subfolder), artifacts)\n",
    "                        # print(orig_artifacts_loc)\n",
    "                        new_artifacts_loc = os.path.join(os.path.join(os.path.join(source_dir, file_name), subfolder), 'artifacts')\n",
    "                        # print(new_artifacts_loc)\n",
    "                        shutil.move(orig_artifacts_loc, new_artifacts_loc)\n",
    "            shutil.move(os.path.join(source_dir, file_name), target_dir)\n",
    "elif platform.system() == 'Linux':\n",
    "    file_names = os.listdir()\n",
    "    current_artifact_base_fpath = os.getcwd()\n",
    "    source_dir = f'{current_artifact_base_fpath}'\n",
    "    target_dir = linux_mlflow_artifact_uri\n",
    "    for file_name in file_names:\n",
    "        if file_name  == exp_num:\n",
    "            for subfolder in os.listdir(file_name):\n",
    "                for artifacts in os.listdir(os.path.join(file_name,subfolder)):\n",
    "                    if artifacts == 'checkpoints':\n",
    "                        orig_artifacts_loc = os.path.join(os.path.join(os.path.join(source_dir, file_name), subfolder), artifacts)\n",
    "                        # print(orig_artifacts_loc)\n",
    "                        new_artifacts_loc = os.path.join(os.path.join(os.path.join(source_dir, file_name), subfolder), 'artifacts')\n",
    "                        # print(new_artifacts_loc)\n",
    "                        shutil.move(orig_artifacts_loc, new_artifacts_loc)\n",
    "            shutil.move(os.path.join(source_dir, file_name), target_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take a look at mlflow for best run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = '045f6c11821145758950e48d2d5d8f1f'\n",
    "if platform.system() == 'Windows':\n",
    "    model_path = f'{mlflow_artifact_uri}\\\\{exp_num}\\\\{run_id}\\\\artifacts'\n",
    "elif platform.system() == 'Linux':\n",
    "    model_path = f'{linux_mlflow_artifact_uri}/{exp_num}/{run_id}/artifacts'\n",
    "for pt in os.listdir(model_path):\n",
    "    if pt.endswith('.ckpt'):\n",
    "        if platform.system() == 'Windows':\n",
    "            ckpt_path = f'{model_path}\\\\{pt}'\n",
    "        elif platform.system() == 'Linux':\n",
    "            ckpt_path = f'{model_path}/{pt}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-mini were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-mini and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TextClassifier.load_from_checkpoint(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative', 'positive']\n"
     ]
    }
   ],
   "source": [
    "# pred_datamodule = TextClassificationData.from_csv(\n",
    "#     predict_file=config['text-example']['predict_file'],\n",
    "#     input_fields=input_fields,\n",
    "# )\n",
    "# predictions = flash.Trainer().predict(model, datamodule=pred_datamodule)\n",
    "# print(predictions)\n",
    "\n",
    "predictions = model.predict([\n",
    "    \"Turgid dialogue, feeble characterization - Harvey Keitel a judge?.\",\n",
    "    \"I come from Bulgaria where it 's almost impossible to have a tornado.\"\n",
    "    \"Very, very afraid\"\n",
    "    \"This guy has done a great job with this movie!\",\n",
    "])\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "64d303618c8ee9f1cee103d362ed2586b5f50e4b11555251f761d52c2b006ae5"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
